{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib\n",
    "import csv\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "import numpy as np\n",
    "from rdflib.namespace import OWL, RDF, RDFS,XSD, Namespace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"https://dbpedia.org/ontology/\"\n",
    "possible_types = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _store_dict(dict_path, list_to_store):\n",
    "    with open(dict_path, 'wt') as file:\n",
    "        writer = csv.writer(file, delimiter='\\t')\n",
    "        for idx, val in enumerate(list_to_store):\n",
    "            writer.writerow([idx, val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_dict_as_list(dict_path):\n",
    "    with open(dict_path) as tsv:\n",
    "        list_to_store = []\n",
    "        reader = csv.reader(tsv, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            list_to_store.append(row[1])\n",
    "        return list_to_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relation_type(relation):\n",
    "    r_split = relation.split(\"/\")\n",
    "    return r_split[len(r_split)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N6d304ea1371f41a0b39f09323e5041d3 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ontology = rdflib.Graph()\n",
    "ontology.parse('data/ontologia.ttl', format='ttl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology.bind(\"dbo\", Namespace(\"http://dbpedia.org/ontology/\"))\n",
    "ontology.bind(\"dbr\", Namespace(\"http://dbpedia.org/resource/\"))\n",
    "ontology.bind(\"rdfs\", Namespace(\"http://www.w3.org/2000/01/rdf-schema#\"))\n",
    "ontology.bind(\"owl\", Namespace(\"http://www.w3.org/2002/07/owl#\"))\n",
    "ontology.bind(\"rdf\", Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possible_types(subj_type, obj_type):\n",
    "    if (subj_type,obj_type) not in possible_types:\n",
    "        q = \"SELECT DISTINCT ?property WHERE {\"+\\\n",
    "        \"{ ?property rdfs:domain dbo:\"+subj_type+\". ?property rdfs:range dbo:\"+obj_type+\\\n",
    "        \" .} UNION {dbo:\"+subj_type +\" rdfs:subClassOf ?superclass. dbo:\"+obj_type +\" rdfs:subClassOf  ?superclass2 .\"+\\\n",
    "        \"  ?property rdfs:domain ?superclass . ?property rdfs:range ?superclass2 \"+\\\n",
    "        \"} }\"\n",
    "        result = ontology.query(q)\n",
    "        results = []\n",
    "        for res in result:\n",
    "            results.append(str(res[0]))\n",
    "        \n",
    "        q2 = \"SELECT DISTINCT ?property WHERE {\"+\\\n",
    "        \"{dbo:\"+subj_type +\" rdfs:subClassOf ?superclass. \"+\\\n",
    "        \" ?property rdfs:domain ?superclass . ?property rdfs:range dbo:\"+obj_type+\\\n",
    "        \" .} UNION {dbo:\"+obj_type +\" rdfs:subClassOf  ?superclass2 . ?property rdfs:domain dbo:\"+\\\n",
    "        subj_type+\" . ?property rdfs:range ?superclass2}}\"\n",
    "        \n",
    "        result = ontology.query(q2)\n",
    "        for res in result:\n",
    "            results.append(str(res[0]))\n",
    "        \n",
    "        possible_types[(subj_type,obj_type)] = results\n",
    "        return results\n",
    "    return possible_types[(subj_type,obj_type)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_and_type = {}\n",
    "relations = []\n",
    "triples = []\n",
    "triple_properties=[]\n",
    "# Process the Knowledge Graph\n",
    "g = rdflib.Graph()\n",
    "g.parse('data/complete.nt', format='nt')\n",
    "total = []\n",
    "for s, p, o in g:\n",
    "    total.append(str(s)+\", \"+ str(p) + \", \"+ str(o))\n",
    "\n",
    "    if str(p) != \"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\":\n",
    "        if not str(s) in entities_and_type.keys():\n",
    "            entities_and_type[(str(s))] =[]\n",
    "        if not str(p) in relations:\n",
    "            relations.append(str(p))\n",
    "\n",
    "        if str(o).find('^^') == -1:\n",
    "            if not str(o) in entities_and_type.keys():\n",
    "                entities_and_type[str(o)]=[]\n",
    "            triples.append((s,p,o))\n",
    "        else:\n",
    "            triple_properties.append((str(s),str(p),str(o)))\n",
    "        \n",
    "    else:\n",
    "        if str(s) not in entities_and_type.keys():\n",
    "            entities_and_type[str(s)] =[]\n",
    "        \n",
    "        split_o = str(o).split('/')\n",
    "        entities_and_type[str(s)].append(split_o[len(split_o)-1])\n",
    "for e in entities_and_type:\n",
    "    entities_and_type[e].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disambiguate_multiple_types(s,p,o): \n",
    "    \n",
    "    for subtype_subj in entities_and_type[str(s)]:\n",
    "\n",
    "        if len(entities_and_type[str(o)]) > 1:\n",
    "            for subtype_obj in entities_and_type[str(o)]:\n",
    "                possible_rels = get_possible_types( subtype_subj, subtype_obj)\n",
    "                if len(possible_rels) == 0:\n",
    "                    return (\"\",\"\")    \n",
    "                for rel in possible_rels:\n",
    "                    if rel == p:\n",
    "                        return (subtype_subj, subtype_obj)\n",
    "        else:\n",
    "            possible_rels = get_possible_types( subtype_subj, entities_and_type[str(o)][0])\n",
    "            if len(possible_rels) == 0:\n",
    "                    return (\"\",\"\")    \n",
    "            for rel in possible_rels:\n",
    "                if rel == p:\n",
    "                    return (subtype_subj, subtype_obj)\n",
    "        \n",
    "    return (\"\",\"\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://dbpedia.org/resource/Adam_Sandler ['Actor', 'Person']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "can't set attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e78a4cf180d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities_and_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mentities_and_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mnew_subj_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_obj_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisambiguate_multiple_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_subj_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_obj_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-91be9eea376d>\u001b[0m in \u001b[0;36mdisambiguate_multiple_types\u001b[0;34m(s, p, o)\u001b[0m\n\u001b[1;32m     12\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msubtype_subj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubtype_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mpossible_rels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_possible_types\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0msubtype_subj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentities_and_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_rels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-82e47ccacaac>\u001b[0m in \u001b[0;36mget_possible_types\u001b[0;34m(subj_type, obj_type)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;34m\"  ?property rdfs:domain ?superclass . ?property rdfs:range ?superclass2 \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;34m\"} }\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0montology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/rdflib/graph.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query_object, processor, result, initNs, initBindings, use_store_provided, **kwargs)\u001b[0m\n\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/rdflib/plugin.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(name, kind)\u001b[0m\n\u001b[1;32m    105\u001b[0m         raise PluginException(\n\u001b[1;32m    106\u001b[0m             \"No plugin registered for (%s, %s)\" % (name, kind))\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/rdflib/plugin.py\u001b[0m in \u001b[0;36mgetClass\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/rdflib/plugins/sparql/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mPLUGIN_ENTRY_POINT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rdf.plugins.sparqleval'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moperators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparserutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/rdflib/plugins/sparql/parser.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;31m# [140] PNAME_NS ::= PN_PREFIX? ':'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m PNAME_NS = Optional(\n\u001b[0;32m--> 184\u001b[0;31m     Param('prefix', PN_PREFIX)) + Suppress(':').leaveWhitespace()\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;31m# [173] PN_LOCAL_ESC ::= '\\' ( '_' | '~' | '.' | '-' | '!' | '$' | '&' | \"'\" | '(' | ')' | '*' | '+' | ',' | ';' | '=' | '/' | '?' | '#' | '@' | '%' )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/rdflib/plugins/sparql/parserutils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, expr, isList)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misList\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mTokenConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: can't set attribute"
     ]
    }
   ],
   "source": [
    "new_triples=[]\n",
    "added_types = []\n",
    "triples.sort()\n",
    "for s,p,o in triples:\n",
    "    if len(entities_and_type[str(s)]) > 1:\n",
    "        new_subj_type, new_obj_type = disambiguate_multiple_types(s,p,o)\n",
    "        if(new_subj_type, new_obj_type) == (\"\",\"\"):\n",
    "            continue\n",
    "        #print(\"news\", new_subj_type, \"newo\", new_obj_type, \"sub\", s, \"obj\", o)\n",
    "        if new_subj_type != \"\" and new_obj_type != \"\":\n",
    "            if s not in added_types:\n",
    "                new_triples.append((s, \"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\",prefix+ new_subj_type[0] ))\n",
    "                added_types.append(s)\n",
    "            if o not in added_types:\n",
    "                new_triples.append((o, \"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\",prefix+ new_obj_type[0] ))\n",
    "                added_types.append(o)\n",
    "            new_triples.append((new_subj_type, p, new_obj_type))\n",
    "    else:  \n",
    "        if s not in added_types:\n",
    "            new_triples.append((s, \"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\",prefix+entities_and_type[str(s)][0] ))\n",
    "            added_types.append(s)\n",
    "        if o not in added_types:\n",
    "            new_triples.append((o, \"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\",prefix+entities_and_type[str(o)][0] ))\n",
    "            added_types.append(o)\n",
    "        new_triples.append((s, p, o))\n",
    "\n",
    "new_triples.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_types_count = {}\n",
    "entities_no_empty = []\n",
    "for entity in entities_and_type:\n",
    "    tipo = entities_and_type[entity].lower()\n",
    "    if tipo != \"\":\n",
    "        entity_types_count[tipo] = entity_types_count.get(tipo, 0)+1\n",
    "        entities_no_empty.append(entity)\n",
    "\n",
    "\n",
    "# Store entities and relations as dictionaries\n",
    "_store_dict(\"entities.dict\", entities_no_empty)\n",
    "_store_dict(\"relations.dict\", relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to create a dataset with:\n",
    "- Homo nodes with OHE\n",
    "- Hetero edges (id for edge types are in a tensor edge_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONE HOT ENCODER AS DISPATCH TABLE\n",
    "OHE = {}\n",
    "for i,key in enumerate(entity_types_count.keys()):\n",
    "    OHE[key] = [1 if j==i else 0 for j in range(len(entity_types_count.keys()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'film': [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 'director': [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " 'city': [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " 'televisionshow': [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " 'actor': [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " 'person': [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " 'productioncompany': [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       " 'country': [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " 'creativework': [0, 0, 0, 0, 0, 0, 0, 0, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entities = _read_dict_as_list(\"entities.dict\")\n",
    "entities = entities_no_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_ohe = {}\n",
    "for i,entity in enumerate(entities):\n",
    "    tipo = entities_and_type[str(entity)].lower()\n",
    "    nodes_ohe[i] = OHE[tipo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_dict = {}\n",
    "object_dict = {}\n",
    "for triple in triples:\n",
    "    s = str(triple[0])\n",
    "    p = str(triple[1])\n",
    "    o = str(triple[2])\n",
    "\n",
    "    if s in entities and o in entities:\n",
    "        p_type = get_relation_type(p)\n",
    "        s_type = entities_and_type[s].lower()\n",
    "        o_type = entities_and_type[o].lower()\n",
    "\n",
    "        if(s_type != \"\" and o_type != \"\"):\n",
    "            key_t = (s_type, p_type, o_type)\n",
    "            if key_t in list(subject_dict.keys()):\n",
    "                subject_dict[key_t].append(entities.index(str(s)))\n",
    "                object_dict[key_t].append(entities.index(str(o)))\n",
    "            else:\n",
    "                subject_dict[key_t] = [entities.index(str(s))]\n",
    "                object_dict[key_t] = [entities.index(str(o))]\n",
    "\n",
    "         \n",
    "        #data[s_type, p_type, o_type].edge_index[0].append(entities.index(str(s)))\n",
    "        #data[s_type, p_type, o_type].edge_index[1].append(entities.index(str(o)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data()\n",
    "#data.x = torch.Tensor([[1] for i in range(len(entities_no_empty))])\n",
    "#data.x = torch.Tensor([node_feature for i,node_feature in sorted(nodes_ohe.items())])\n",
    "\"\"\"Feature strutturali\"\"\"\n",
    "data.x = torch.Tensor([[] for i in range(len(entities_no_empty))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[12225, 9])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol = [[],[]]\n",
    "edge_type_name = []\n",
    "edge_type = []\n",
    "num_rel=0\n",
    "for triple in subject_dict.keys():\n",
    "    lol[0].extend(subject_dict[triple])\n",
    "    lol[1].extend(object_dict[triple])\n",
    "    edge_type_name.extend([triple[1] for j in range(len(subject_dict[triple]))])\n",
    "    edge_type.extend([num_rel for j in range(len(subject_dict[triple]))])\n",
    "    num_rel+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.edge_index = torch.Tensor(lol).long()\n",
    "data.edge_type = torch.Tensor(edge_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[12225, 9], edge_index=[2, 20573], edge_type=[20573])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import LocalDegreeProfile\n",
    "\n",
    "transform = LocalDegreeProfile()\n",
    "data = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[12225, 14], edge_index=[2, 20573], edge_type=[20573])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R-GCN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import RGCNConv\n",
    "\n",
    "class RGCN(torch.nn.Module):\n",
    "    def __init__(self,num_rel):\n",
    "        super().__init__()\n",
    "        self.conv1 = RGCNConv(data.num_features,4,num_rel) #num_rel := number of edge_types\n",
    "        self.conv2 = RGCNConv(4,2,num_rel)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        x = self.conv1(x,edge_index,edge_type)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x,edge_index,edge_type)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform random link split\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "link_split = RandomLinkSplit(num_val=0.0,num_test=0.25)\n",
    "train_link, val_link, test_link = link_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_in_test = list([(int(z),int(w)) for z, w in \n",
    "                zip(test_link.edge_label_index[0][:test_link.edge_label_index.size(1)//2],\n",
    "                                                  test_link.edge_label_index[1][:test_link.edge_label_index.size(1)//2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_in_data = [(int(x),int(y)) for x,y in zip(data.edge_index[0],data.edge_index[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_of_edges_in_test = [edges_in_data.index(edges_in_test[i]) for i in range(len(edges_in_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_type = train_link.edge_type\n",
    "edge_type_neg = torch.Tensor([randint(0,num_rel-1) for i in range(train_link.edge_label.size(0)//2)])\n",
    "train_link.edge_label_type = torch.cat((edge_type,edge_type_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_type = data.edge_type[index_of_edges_in_test]\n",
    "edge_type_neg = torch.Tensor([randint(0,num_rel-1) for i in range(test_link.edge_label.size(0)//2)])\n",
    "test_link.edge_label_type = torch.cat((edge_type,edge_type_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_weight = torch.nn.Parameter(torch.randn(num_rel, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training end\n"
     ]
    }
   ],
   "source": [
    "model = RGCN(num_rel)\n",
    "model.reset_parameters()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion =  torch.nn.BCEWithLogitsLoss() #change loss function\n",
    "\n",
    "def train_linkpre():\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    out = model(train_link.x, train_link.edge_index, train_link.edge_type)  # Perform a single forward pass.\n",
    "    \n",
    "    ### LINK PREDICTION ACTS HERE ###\n",
    "    \n",
    "    out_src = out[train_link.edge_label_index[0]] #embedding src nodes\n",
    "    out_dst = out[train_link.edge_label_index[1]] #embedding dst nodes\n",
    "    \n",
    "    # LINK EMBEDDING #\n",
    "    # 1 - Dot Product\n",
    "    #out_sim = out_src * out_dst #dotproduct\n",
    "    #pred = torch.sum(out_sim, dim=-1)\n",
    "    \n",
    "    # 2 - Concatenation + linear function\n",
    "    #out_sim = torch.cat([out_src, out_dst], dim=-1)\n",
    "    #pred = torch.sum(out_sim,dim=-1)\n",
    "    \n",
    "    # 3 - DistMult\n",
    "    pred = torch.sum(out_src * rel_weight[train_link.edge_label_type.long()]* out_dst, dim=-1)\n",
    "    \n",
    "    \n",
    "    loss = criterion(pred, train_link.edge_label.type_as(pred)) \n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    return loss\n",
    "\n",
    "def test_linkpre(test_link):\n",
    "    model.eval()\n",
    "    out = model(test_link.x, test_link.edge_index, test_link.edge_type)\n",
    "    \n",
    "    ### LINK PREDICTION ACTS HERE ###\n",
    "    \n",
    "    out_src = out[test_link.edge_label_index[0]] #embedding src nodes\n",
    "    out_dst = out[test_link.edge_label_index[1]] #embedding dst nodes\n",
    "    \n",
    "    # LINK EMBEDDING #\n",
    "    # 1 - Dot Product\n",
    "    #out_sim = out_src * out_dst\n",
    "    #h = torch.sum(out_sim, dim=-1)\n",
    "    \n",
    "    # 2 - Concatenation + linear function\n",
    "    #out_sim = torch.cat([out_src, out_dst], dim=-1)\n",
    "    #h = torch.sum(out_sim,dim=-1)\n",
    "    \n",
    "    # 3 - DistMult\n",
    "    h = torch.sum(out_src * rel_weight[test_link.edge_label_type.long()]* out_dst, dim=-1)\n",
    "    \n",
    "    pred_cont = torch.sigmoid(h).cpu().detach().numpy()\n",
    "    \n",
    "    # EVALUATION\n",
    "    test_label = test_link.edge_label.cpu().detach().numpy() #retrieve test set labels\n",
    "    test_roc_score = roc_auc_score(test_label, pred_cont) #comput AUROC score for test set\n",
    "    \n",
    "    return test_roc_score\n",
    "\n",
    "\n",
    "for epoch in range(1, 801):\n",
    "    loss = train_linkpre()\n",
    "    #print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "print('Training end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUROC: 0.9210\n",
      "Test AUROC: 0.8249\n"
     ]
    }
   ],
   "source": [
    "roc_train = test_linkpre(train_link)\n",
    "roc_test = test_linkpre(test_link)\n",
    "print(f'Train AUROC: {roc_train:.4f}\\nTest AUROC: {roc_test:.4f}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
